# Scanntech Challenge
# Panel de Control RAG con Gemini y MÃ©tricas de Calidad ğŸš€

Este proyecto fue desarrollado en el marco de un desafÃ­o tÃ©cnico propuesto por Scanntech. Es un sistema que principalmente estÃ¡ compuesto por un chatbot basado en **RAG** (Retrieval-Augmented Generation) que responde preguntas sobre el libro "An Introduction to Statistical Learning with Applications in Python".

AdemÃ¡s de ser un simple chatbot, este proyecto implementa un **Panel de Control** que permite monitorear, evaluar y mejorar la calidad del sistema RAG a travÃ©s de mÃ©tricas en tiempo real y evaluaciones exhaustivas bajo demanda.

## Preview

![Panel de Control RAG](media/panel_de_control.png) 

## Ãndice

- [Panel de Control RAG: Features Principales](#panel-de-control-rag-features-principales)
- [Sistema de EvaluaciÃ³n Dual](#sistema-de-evaluaciÃ³n-dual)
- [Stack TecnolÃ³gico](#stack-tecnolÃ³gico)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Despliegue en Railway con Docker](#despliegue-en-railway-con-docker)

## Panel de Control RAG: Features Principales

La aplicaciÃ³n se presenta como un panel de control con tres secciones principales, diseÃ±adas para interactuar con el agente y analizar su rendimiento.

### 1. Chat Interactivo
Una interfaz de chat construida con React que permite a los usuarios conversar con el agente. Incluye:
- **Memoria de ConversaciÃ³n**: El historial del chat se envÃ­a al agente para mantener el contexto.
- **BÃºsqueda SemÃ¡ntica**: El agente utiliza Pinecone para buscar en el libro y basar sus respuestas en la informaciÃ³n recuperada.
- **Persistencia de Conversaciones**: Todos los mensajes (usuario y agente) se almacenan en una base de datos PostgreSQL.

### 2. MÃ©tricas de ConversaciÃ³n (MÃ©tricas Online)
Una vista de tabla que muestra las mÃ©tricas de calidad de las conversaciones reales de los usuarios, calculadas en tiempo real.
- **EvaluaciÃ³n AutomÃ¡tica**: Cada respuesta del bot se evalÃºa en segundo plano para no afectar la experiencia del usuario.
- **MÃ©tricas Clave**: Se miden `faithfulness` (fidelidad, para detectar alucinaciones) y `answer_relevancy` (relevancia de la respuesta).
- **Contexto Completo**: La tabla muestra la pregunta del usuario, la respuesta del bot y sus respectivos scores, permitiendo un diagnÃ³stico rÃ¡pido de problemas.

### 3. EvaluaciÃ³n del Sistema (Monitoreo Offline)
Una secciÃ³n dedicada a ejecutar una evaluaciÃ³n profunda y controlada del sistema RAG.
- **Golden Dataset**: Utiliza un conjunto de datos curado de preguntas y respuestas "correctas" almacenado en PostgreSQL.
- **EjecuciÃ³n "Offline"**: Una interfaz donde se  un script que corre todo el dataset de evaluaciÃ³n contra el sistema RAG.
- **Reporte Completo**: Muestra un reporte detallado con mÃ©tricas avanzadas como `context_precision`, `context_recall` y `answer_correctness`, permitiendo validar objetivamente la calidad de los componentes de retrieval y generaciÃ³n.

## Sistema de EvaluaciÃ³n Dual

El corazÃ³n de este proyecto es su enfoque no solo en brindar una interfaz para conversar, sino en la posibilidad de evaluar las respuestas utilizando la librerÃ­a **Ragas** para implementar dos bucles de evaluaciÃ³n complementarios:

- **MÃ©tricas Online:** Proporciona una visiÃ³n constante de la performance del bot en producciÃ³n, detectando problemas en conversaciones reales a travÃ©s de mÃ©tricas sin referencia.
- **Monitoreo Offline:** Permite a los desarrolladores medir la calidad del sistema en un entorno controlado, comparar versiones de prompts y validar mejoras de forma cientÃ­fica antes de desplegarlas.

## Stack TecnolÃ³gico

- **Frontend**:
  - **LibrerÃ­a/Framework**: React, Vite
  - **Estilos**: CSS puro

- **Backend**:
  - **Framework**: Python, Flask
  - **Base de Datos Relacional**: PostgreSQL
  - **ORM y Migraciones**: SQLAlchemy, Flask-Migrate
  - **Servidor WSGI**: Gunicorn

- **IA**:
  - **Modelo de Lenguaje**: Google Gemini (`gemini-2.0-flash`)
  - **Base de Datos Vectorial**: Pinecone
  - **Modelo de Embeddings**: OpenAI (`text-embedding-3-small`)
  - **LibrerÃ­a de EvaluaciÃ³n RAG**: Ragas

- **Despliegue**:
  - **Plataforma**: Railway
  - **ContenerizaciÃ³n**: **Docker**

## Estructura del Proyecto

El proyecto estÃ¡ organizado como un monorepo con dos directorios principales:

```
/
â”œâ”€â”€ backend/                       # CÃ³digo del servidor Flask
â”‚   â”œâ”€â”€ data/                      # Libro en .pdf
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/                   # LÃ³gica de la aplicaciÃ³n, modelos y herramientas
â”‚   â”‚   â””â”€â”€ services/              # Se encuentra alojado el vectorize_pdf.py
â”‚   â”œâ”€â”€ migrations/                # Scripts de migraciÃ³n de la base de datos
â”‚   â”œâ”€â”€ Dockerfile                 # Define el entorno de producciÃ³n con Docker
â”‚   â”œâ”€â”€ .dockerignore              # Excluye archivos innecesarios de la imagen Docker
â”‚   â”œâ”€â”€ main.py                    # Punto de entrada de la aplicaciÃ³n Flask
â”‚   â”œâ”€â”€ run_evaluations.py         # Script para la evaluaciÃ³n offline
â”‚   â”œâ”€â”€ create_golden_dataset.py   # Script para crear el golden dataset
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/                      # CÃ³digo de la aplicaciÃ³n de React
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/                   # Funciones para llamar al backend
â”‚   â”‚   â”œâ”€â”€ components/            # Componentes, pÃ¡ginas y estilos
â”‚   â”‚   â”œâ”€â”€ App.jsx                # Orquestador de rutas
â”‚   â”‚   â””â”€â”€ main.jsx               # Punto de entrada de la aplicaciÃ³n React
â”‚   â””â”€â”€ ...
â”œâ”€â”€ media/                         # Archivos complementarios
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## Despliegue en Railway con Docker

Este proyecto estÃ¡ diseÃ±ado para ser desplegado de forma robusta y consistente en la plataforma **Railway** utilizando **Docker**. La contenerizaciÃ³n asegura que el entorno de ejecuciÃ³n sea idÃ©ntico sin importar dÃ³nde se despliegue, eliminando problemas de dependencias de sistema (como la necesidad de `git` para la librerÃ­a `ragas`).

### ConfiguraciÃ³n en Railway

1.  **Crear el Proyecto**: Sube tu repositorio a GitHub y crea un nuevo proyecto en Railway a partir de Ã©l.
2.  **AÃ±adir Base de Datos**: Dentro del proyecto de Railway, aÃ±ade un nuevo servicio de base de datos **PostgreSQL**. Railway inyectarÃ¡ automÃ¡ticamente la variable de entorno `DATABASE_URL` en tus otros servicios.
3.  **Configurar Variables de Entorno**: En el servicio `backend`, ve a la pestaÃ±a "Variables" y configura las siguientes claves secretas:

    ```ini
    # Clave de API de Google para el modelo Gemini
    GOOGLE_API_KEY="tu_clave_de_google"

    # Claves de API para Pinecone
    PINECONE_API_KEY="tu_clave_de_pinecone"

    # Clave de API para OpenAI (usado para los embeddings)
    OPENAI_API_KEY="tu_clave_de_openai"
    
    # OrÃ­genes permitidos para CORS (la URL de tu frontend desplegado)
    ALLOWED_ORIGINS="https://tu-frontend.up.railway.app" 
    ```

4.  **Configurar Directorio RaÃ­z (Â¡Importante!)**: Como este es un monorepo, debes indicarle a Railway dÃ³nde encontrar el backend. En los `Settings` del servicio `backend`, en la secciÃ³n `Build`, establece el **Root Directory** en `backend/`.

5.  **Desplegar**: Â¡Y listo! Con las variables y el directorio raÃ­z configurados, cualquier `git push` a tu rama principal dispararÃ¡ un nuevo despliegue. Railway detectarÃ¡ automÃ¡ticamente el `Dockerfile` dentro de `backend/`, construirÃ¡ la imagen, y la pondrÃ¡ en lÃ­nea. El comando `CMD` dentro del `Dockerfile` se encarga de aplicar las migraciones (`flask db upgrade`) y luego iniciar el servidor (`gunicorn main:app`).